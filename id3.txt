import csv
import math

def major_class(attributes, data, target):
    freq = {}
    index = attributes.index(target)
    for t in data:
        if t[index] in freq:
            freq[t[index]] += 1
        else:
            freq[t[index]] = 1
    m = 0
    major = ""
    for key in freq.keys():
        if freq[key] > m:
            m = freq[key]
            major = key
    return major

def entropy(attributes, data, targetAttr):
    freq = {}
    data_entropy = 0.0
    i = attributes.index(targetAttr)
    for entry in data:
        if entry[i] in freq:
            freq[entry[i]] += 1.0
        else:
            freq[entry[i]] = 1.0
    for f in freq.values():
        data_entropy += (-f/len(data)) * math.log(f/len(data), 2)
    return data_entropy

def info_gain(attributes, data, attr, targetAttr):
    freq = {}
    subset_entropy = 0.0
    i = attributes.index(attr)
    for entry in data:
        if entry[i] in freq:
            freq[entry[i]] += 1.0
        else:
            freq[entry[i]] = 1.0
    for val in freq.keys():
        val_prob = freq[val] / sum(freq.values())
        data_subset = [entry for entry in data if entry[i] == val]
        subset_entropy += val_prob * entropy(attributes, data_subset, targetAttr)
    return entropy(attributes, data, targetAttr) - subset_entropy

def attr_choose(data, attributes, target):
    best = attributes[0]
    max_gain = 0
    for attr in attributes:
        if attr != target:
            new_gain = info_gain(attributes, data, attr, target)
            if new_gain > max_gain:
                max_gain = new_gain
                best = attr
    return best

def get_values(data, attributes, attr):
    i = attributes.index(attr)
    values = []
    for entry in data:
        if entry[i] not in values:
            values.append(entry[i])
    return values

def get_data(data, attributes, best, val):
    new_data = []
    i = attributes.index(best)
    for entry in data:
        if entry[i] == val:
            new_entry = []
            for j in range(len(entry)):
                if j != i:
                    new_entry.append(entry[j])
            new_data.append(new_entry)
    return new_data

def build_tree(data, attributes, target):
    data = data[:]
    vals = [record[attributes.index(target)] for record in data]
    default = major_class(attributes, data, target)
    if not data or (len(attributes) - 1) <= 0:
        return default
    elif vals.count(vals[0]) == len(vals):
        return vals[0]
    else:
        best = attr_choose(data, attributes, target)
        tree = {best: {}}
        for val in get_values(data, attributes, best):
            new_data = get_data(data, attributes, best, val)
            new_attr = attributes[:]
            new_attr.remove(best)
            subtree = build_tree(new_data, new_attr, target)
            tree[best][val] = subtree
    return tree

def test(attributes, instance, tree):
    attribute = next(iter(tree))
    i = attributes.index(attribute)
    if instance[i] in tree[attribute].keys():
        result = tree[attribute][instance[i]]
        if isinstance(result, dict):
            return test(attributes, instance, result)
        else:
            return result
    else:
        return 'NULL'

def execute_decision_tree():
    data = []
    with open('datasets/PlayTennis.csv') as tsv:
        for line in csv.reader(tsv):
            data.append(tuple(line))
        print('Number of records: ', len(data))

    attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind', 'PlayTennis']
    target = attributes[-1]
    training_set = [x for i, x in enumerate(data) if i != 0]  # Exclude header
    print("Training Set: ", training_set)
    tree = build_tree(training_set, attributes, target)
    print('Decision Tree is as below: \n')
    print(tree)
    instance = ['Rain', 'Mild', 'High', 'Strong']
    print('Testing instance is: ', instance)
    result = test(attributes, instance, tree)
    print('The Target value for the testing instance is: ')
    print(result)

execute_decision_tree()

# import csv
# from math import log2

# def get_data(file):
#     with open(file) as csv_file:
#         csv_reader = csv.reader(csv_file)
#         data = list(csv_reader)
#         for line in data:
#             print(line)
#     return data[1:], data[0]

# def entropy(data):
#     outcomes = [row[-1] for row in data]
#     probs = [outcomes.count(value) / len(outcomes) for value in set(outcomes)]
#     return -sum(p * log2(p) for p in probs)

# def split_data(data, attr):
#     values = set(row[attr] for row in data)
#     return [[row for row in data if row[attr] == value] for value in values]

# def best_attribute(data):
#     base_entropy = entropy(data)
#     gain = [(base_entropy - sum((len(subset) / len(data)) * entropy(subset) for subset in split_data(data, attr)), attr) for attr in range(len(data[0]) - 1)]
#     return max(gain)[1]

# def decision_tree(data, labels):
#     outcomes = [row[-1] for row in data]
#     if outcomes.count(outcomes[0]) == len(outcomes):
#         return outcomes[0]
#     attr = best_attribute(data)
#     tree = {labels[attr]: {}}

#     for value in set(row[attr] for row in data):
#         sub_labels = labels[:attr] + labels[attr+1:]
#         sub_data = [row[:attr] + row[attr+1:] for row in data if row[attr] == value]

#         tree[labels[attr]][value] = decision_tree(sub_data, sub_labels)
        
#     return tree

# data, labels = get_data("weather.csv")
# tree = decision_tree(data, labels)
# print("\nDecision Tree:", tree)

